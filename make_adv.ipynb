{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "infinite-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from os.path import dirname\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from utils.models import PreprocessLayer\n",
    "from utils.models import Classifier\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.loader import Loader\n",
    "from utils.loss import cross_entropy_loss_and_accuracy\n",
    "from utils.dataset import NCaltech101\n",
    "from torch.utils.data.dataloader import default_collate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "academic-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(777)\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "resident-launch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Starting training with \n",
      "num_epochs: 2\n",
      "batch_size: 4\n",
      "device: cuda:0\n",
      "log_dir: /ws/external/log_1.4_b4/temp\n",
      "training_dataset: /ws/data/N-Caltech101/training/\n",
      "validation_dataset: /ws/data/N-Caltech101/validation/\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "validation_dataset=\"/ws/data/N-Caltech101/validation/\"\n",
    "training_dataset=\"/ws/data/N-Caltech101/training/\"\n",
    "log_dir=\"/ws/external/log_1.4_b4/temp\"\n",
    "device=\"cuda:0\"\n",
    "num_workers=4\n",
    "pin_memory=True\n",
    "batch_size=4\n",
    "num_epochs=2\n",
    "save_every_n_epochs=2\n",
    "checkpoint = \"/ws/external/log_1.4_b4/model_best.pth\" # model_best.pth checkpoint_13625_0.5990.pth\n",
    "    \n",
    "    \n",
    "assert os.path.isdir(dirname(log_dir)), f\"Log directory root {dirname(log_dir)} not found.\"\n",
    "assert os.path.isdir(validation_dataset), f\"Validation dataset directory {validation_dataset} not found.\"\n",
    "assert os.path.isdir(training_dataset), f\"Training dataset directory {training_dataset} not found.\"\n",
    "\n",
    "print(f\"----------------------------\\n\"\n",
    "      f\"Starting training with \\n\"\n",
    "      f\"num_epochs: {num_epochs}\\n\"\n",
    "      f\"batch_size: {batch_size}\\n\"\n",
    "      f\"device: {device}\\n\"\n",
    "      f\"log_dir: {log_dir}\\n\"\n",
    "      f\"training_dataset: {training_dataset}\\n\"\n",
    "      f\"validation_dataset: {validation_dataset}\\n\"\n",
    "      f\"----------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "executed-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile(t, q):\n",
    "    B, C, H, W = t.shape\n",
    "    k = 1 + round(.01 * float(q) * (C * H * W - 1))\n",
    "    result = t.view(B, -1).kthvalue(k).values\n",
    "    return result[:,None,None,None]\n",
    "\n",
    "def create_image(representation):\n",
    "    B, C, H, W = representation.shape\n",
    "    representation = representation.view(B, 3, C // 3, H, W).sum(2)\n",
    "\n",
    "    # do robust min max norm\n",
    "    representation = representation.detach().cpu()\n",
    "    robust_max_vals = percentile(representation, 99)\n",
    "    robust_min_vals = percentile(representation, 1)\n",
    "\n",
    "    representation = (representation - robust_min_vals)/(robust_max_vals - robust_min_vals)\n",
    "    representation = torch.clamp(255*representation, 0, 255).byte()\n",
    "\n",
    "    representation = torchvision.utils.make_grid(representation)\n",
    "\n",
    "    return representation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "regulation-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    def __init__(self, dataset, batch_size=2, num_workers=2, pin_memory=True, device=\"cuda:0\"):\n",
    "        self.device = device\n",
    "        split_indices = list(range(len(dataset)))\n",
    "        sampler = torch.utils.data.sampler.SubsetRandomSampler(split_indices)\n",
    "        self.loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=sampler,\n",
    "                                             num_workers=num_workers, pin_memory=pin_memory,\n",
    "                                             collate_fn=collate_events)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for data in self.loader:\n",
    "            data = [d.to(self.device) for d in data]\n",
    "            yield data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "def collate_events(data):\n",
    "    labels = []\n",
    "    events = []\n",
    "    for i, d in enumerate(data):\n",
    "        labels.append(d[1])\n",
    "        ev = np.concatenate([d[0], i*np.ones((len(d[0]),1), dtype=np.float32)],1)\n",
    "        events.append(ev)\n",
    "    events = torch.from_numpy(np.concatenate(events,0))\n",
    "    labels = default_collate(labels)\n",
    "    return events, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "revised-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets, add augmentation to training set\n",
    "training_dataset = NCaltech101(training_dataset, augmentation=True)\n",
    "validation_dataset = NCaltech101(validation_dataset)\n",
    "\n",
    "# construct loader, handles data streaming to gpu\n",
    "training_loader = Loader(training_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, device=\"cuda:0\")\n",
    "validation_loader = Loader(validation_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "timely-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, and put to device\n",
    "preprocess = PreprocessLayer()\n",
    "model = Classifier(pretrained=False)\n",
    "ckpt = torch.load(checkpoint)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model = model.to(device)\n",
    "\n",
    "# # optimizer and lr scheduler\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.5)\n",
    "\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "iteration = 0\n",
    "min_validation_loss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "complete-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (events, labels) = next(enumerate(validation_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eight-limitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([624273, 5])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "indie-iceland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([67, 21, 63, 41], device='cuda:0')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "resistant-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.zero_grad()\n",
    "t = preprocess(events)\n",
    "pred_labels, representation = model(events, t)\n",
    "loss, accuracy = cross_entropy_loss_and_accuracy(pred_labels, labels)\n",
    "# loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "satisfactory-chicken",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([97, 21, 63, 12], device='cuda:0')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "determined-leader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 101])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a50d24dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([67, 21, 63, 41], device='cuda:0')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "precise-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# representation_vizualization = create_image(representation)\n",
    "# writer.add_image(\"training/representation\", representation_vizualization, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0489bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead93a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c089a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "least-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SCALE=255\n",
    "\n",
    "class PGDAttacker():\n",
    "    def __init__(self, model, num_iter, epsilon, step_size, kernel_size=15, \n",
    "                 prob_start_from_clean=0.0, translation=False, num_classes=101, device='cuda:0'):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        step_size = max(step_size, epsilon / num_iter)\n",
    "        self.num_iter = num_iter\n",
    "        self.epsilon = epsilon * IMAGE_SCALE\n",
    "        self.step_size = step_size*IMAGE_SCALE\n",
    "        self.prob_start_from_clean = prob_start_from_clean\n",
    "        self.device = device\n",
    "        self.translation = translation\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "\n",
    "        if translation:\n",
    "            # this is equivalent to deepth wise convolution\n",
    "            # details can be found in the docs of Conv2d.\n",
    "            # \"When groups == in_channels and out_channels == K * in_channels, where K is a positive integer, this operation is also termed in literature as depthwise convolution.\"\n",
    "            self.conv = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=kernel_size, stride=(kernel_size-1)//2, bias=False, groups=3).to(self.device)\n",
    "            self.gkernel = get_kernel(kernel_size, nsig=3, device=self.device).to(self.device)\n",
    "            self.conv.weight = self.gkernel\n",
    "\n",
    "    def _create_random_target(self, label):\n",
    "        label_offset = torch.randint_like(label, low=0, high=self.num_classes)\n",
    "        return (label + label_offset) % self.num_classes\n",
    "\n",
    "    def attack(self, events, label, t, original=False, mode='pgd'):\n",
    "        if mode == 'pgd':\n",
    "            return self.pgd_attack(events, label, t, original=False)\n",
    "\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def pgd_attack(self, events, label, t, original=False):\n",
    "        \"\"\"\n",
    "        aux_images, _ = self.attacker.attack(x, labels, self._forward_impl)\n",
    "        \"\"\"\n",
    "        if original:\n",
    "            target_label = label    # untargeted\n",
    "        else:\n",
    "            target_label = self._create_random_target(label)    # targeted\n",
    "#         lower_bound = torch.clamp(image_clean - self.epsilon, min=-1., max=1.)\n",
    "#         upper_bound = torch.clamp(image_clean + self.epsilon, min=-1., max=1.)\n",
    "\n",
    "        ori_images = t.clone().detach()\n",
    "\n",
    "        init_start = torch.empty_like(t).uniform_(-self.epsilon, self.epsilon)\n",
    "        \n",
    "#         start_from_noise_index = (torch.randn([])>self.prob_start_from_clean).float() \n",
    "#         start_adv = t + start_from_noise_index * init_start\n",
    "        \n",
    "        start_adv = t\n",
    "\n",
    "        adv = start_adv\n",
    "        adv.requires_grad = True\n",
    "        for i in range(self.num_iter):\n",
    "            \n",
    "            logits, representation = self.model(events, adv)\n",
    "            \n",
    "            losses = torch.nn.functional.cross_entropy(logits, target_label)\n",
    "            g = torch.autograd.grad(losses, adv, \n",
    "                                    retain_graph=False, create_graph=False)[0]\n",
    "            if self.translation:\n",
    "                g = self.conv(g)\n",
    "            # Linf step\n",
    "            if original:\n",
    "                adv = adv + torch.sign(g) * self.step_size  # untargeted\n",
    "            else:\n",
    "                adv = adv - torch.sign(g) * self.step_size  # targeted\n",
    "#             # Linf project\n",
    "#             adv = torch.where(adv > lower_bound, adv, lower_bound).detach()\n",
    "#             adv = torch.where(adv < upper_bound, adv, upper_bound).detach()\n",
    "        \n",
    "        return adv, target_label, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "premier-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 2\n",
    "epsilon = 1\n",
    "step_size = 0.5\n",
    "attacker = PGDAttacker(model, num_iter, epsilon, step_size, kernel_size=15, \n",
    "            prob_start_from_clean=0.0, translation=False, num_classes=101, device='cuda:0')\n",
    "adv, target_label, t = attacker.attack(events, labels, t, original=False, mode='pgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "pacific-anthony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([624273])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "caring-scott",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([624273, 5])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "supported-double",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -79.8654, -132.1838, -150.6050,  ...,  -94.5678,  -95.1334,\n",
       "         -81.0742], device='cuda:0')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "changing-torture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([624273])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(init_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f5541377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 101])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1c2ae242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([624273])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a384068e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([23, 89, 30, 79], device='cuda:0')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b1695e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([67, 21, 63, 41], device='cuda:0')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "delayed-february",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: Train classifier using a learnt quantization layer. [-h]\n",
      "                                                           --validation_dataset\n",
      "                                                           VALIDATION_DATASET\n",
      "                                                           --training_dataset\n",
      "                                                           TRAINING_DATASET\n",
      "                                                           --log_dir LOG_DIR\n",
      "                                                           [--device DEVICE]\n",
      "                                                           [--num_workers NUM_WORKERS]\n",
      "                                                           [--pin_memory PIN_MEMORY]\n",
      "                                                           [--batch_size BATCH_SIZE]\n",
      "                                                           [--num_epochs NUM_EPOCHS]\n",
      "                                                           [--save_every_n_epochs SAVE_EVERY_N_EPOCHS]\n",
      "Train classifier using a learnt quantization layer.: error: the following arguments are required: --validation_dataset, --training_dataset, --log_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(num_epochs):\n",
    "    sum_accuracy = 0\n",
    "    sum_loss = 0\n",
    "    model = model.eval()\n",
    "\n",
    "    print(f\"Validation step [{i:3d}/{num_epochs:3d}]\")\n",
    "    for events, labels in tqdm.tqdm(validation_loader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_labels, representation = model(events)\n",
    "            loss, accuracy = cross_entropy_loss_and_accuracy(pred_labels, labels)\n",
    "\n",
    "        sum_accuracy += accuracy\n",
    "        sum_loss += loss\n",
    "\n",
    "    validation_loss = sum_loss.item() / len(validation_loader)\n",
    "    validation_accuracy = sum_accuracy.item() / len(validation_loader)\n",
    "\n",
    "    writer.add_scalar(\"validation/accuracy\", validation_accuracy, iteration)\n",
    "    writer.add_scalar(\"validation/loss\", validation_loss, iteration)\n",
    "\n",
    "    # visualize representation\n",
    "    representation_vizualization = create_image(representation)\n",
    "    writer.add_image(\"validation/representation\", representation_vizualization, iteration)\n",
    "\n",
    "    print(f\"Validation Loss {validation_loss:.4f}  Accuracy {validation_accuracy:.4f}\")\n",
    "\n",
    "    if validation_loss < min_validation_loss:\n",
    "        min_validation_loss = validation_loss\n",
    "        state_dict = model.state_dict()\n",
    "\n",
    "        torch.save({\n",
    "            \"state_dict\": state_dict,\n",
    "            \"min_val_loss\": min_validation_loss,\n",
    "            \"iteration\": iteration\n",
    "        }, \"log/model_best.pth\")\n",
    "        print(\"New best at \", validation_loss)\n",
    "\n",
    "    if i % save_every_n_epochs == 0:\n",
    "        state_dict = model.state_dict()\n",
    "        torch.save({\n",
    "            \"state_dict\": state_dict,\n",
    "            \"min_val_loss\": min_validation_loss,\n",
    "            \"iteration\": iteration\n",
    "        }, \"log/checkpoint_%05d_%.4f.pth\" % (iteration, min_validation_loss))\n",
    "\n",
    "    sum_accuracy = 0\n",
    "    sum_loss = 0\n",
    "\n",
    "    model = model.train()\n",
    "    print(f\"Training step [{i:3d}/{num_epochs:3d}]\")\n",
    "    for events, labels in tqdm.tqdm(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_labels, representation = model(events)\n",
    "        loss, accuracy = cross_entropy_loss_and_accuracy(pred_labels, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_accuracy += accuracy\n",
    "        sum_loss += loss\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    if i % 10 == 9:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    training_loss = sum_loss.item() / len(training_loader)\n",
    "    training_accuracy = sum_accuracy.item() / len(training_loader)\n",
    "    print(f\"Training Iteration {iteration:5d}  Loss {training_loss:.4f}  Accuracy {training_accuracy:.4f}\")\n",
    "\n",
    "    writer.add_scalar(\"training/accuracy\", training_accuracy, iteration)\n",
    "    writer.add_scalar(\"training/loss\", training_loss, iteration)\n",
    "\n",
    "    representation_vizualization = create_image(representation)\n",
    "    writer.add_image(\"training/representation\", representation_vizualization, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-skill",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
